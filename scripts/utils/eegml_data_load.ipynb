{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "import pandas as pd\n",
    "from joblib import Memory\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "BASE_DATA_DIR = '../raw_data'\n",
    "SAMPLING_RATE = 400\n",
    "cache_directory = './cache'\n",
    "mem = Memory(cachedir=cache_directory, verbose=0)\n",
    "\n",
    "def create_files_df():\n",
    "\n",
    "    def pathToSeries(path):\n",
    "        m = re.search('/(.*)_(.*)_(.*).mat',path)\n",
    "        if 'train' in path: \n",
    "            train = 1\n",
    "            patient = int(m.group(1))\n",
    "            preictal = int(m.group(3))\n",
    "        else: \n",
    "            train = 0\n",
    "            patient = int(m.group(2))\n",
    "            preictal = -1\n",
    "\n",
    "        m = re.search('(.*)/(.*)',path)\n",
    "        dir_name = m.group(1)\n",
    "        file_name = m.group(2)\n",
    "        return pd.Series({'path':path,'train':train,'preictal':preictal, 'patient':patient,\n",
    "                         'dir_name': dir_name,'file_name':file_name})\n",
    "\n",
    "    # Get Metadata for all files in raw data directory. \n",
    "    data_dirs = [name for name in os.listdir(BASE_DATA_DIR) if \n",
    "                 os.path.isdir(os.path.join(BASE_DATA_DIR, name))]\n",
    "    paths = [[os.path.join(data_dir, name) for name in os.listdir(os.path.join(BASE_DATA_DIR,data_dir))] \n",
    "             for data_dir in data_dirs] \n",
    "    paths = [j for i in paths for j in i] # flatten to 1d\n",
    "    paths = [i for i in paths if '.DS_Store' not in i]\n",
    "    files_df = pd.DataFrame([pathToSeries(p) for p in paths])\n",
    "\n",
    "    # Filter training files by safe labels. \n",
    "    safe_labels = pd.read_csv(os.path.join(BASE_DATA_DIR, 'train_and_test_data_labels_safe.csv'))\n",
    "    filt_df = files_df\n",
    "    filt_df = filt_df.merge(safe_labels,how='left',left_on='file_name', right_on ='image')\n",
    "    filt_df = filt_df[(filt_df['train']==0) | ((filt_df['train']==1) & (filt_df['safe']==1.0))]\n",
    "    filt_df = filt_df.drop(['image','class','safe'],axis=1)\n",
    "\n",
    "    # Final processing. \n",
    "    files_df = filt_df\n",
    "    files_df = files_df.reset_index(drop=True)\n",
    "    files_df['file_id'] = np.arange(0,files_df.shape[0])\n",
    "\n",
    "    return files_df\n",
    "\n",
    "def load_temporal_data(path):\n",
    "    try: \n",
    "        mat = loadmat(os.path.join(BASE_DATA_DIR,path))\n",
    "        data = mat['dataStruct']['data'][0][0].transpose()\n",
    "        time = np.arange(0,data.shape[1],1/SAMPLING_RATE)\n",
    "        return time, data\n",
    "    except:\n",
    "        return np.empty(0), np.empty(0)\n",
    "\n",
    "@mem.cache\n",
    "def load_power_data(path):\n",
    "    _, temporal_data = load_temporal_data(path)\n",
    "    if temporal_data.size == 0:\n",
    "        return np.empty(0), np.empty(0)\n",
    "    n = temporal_data.shape[1]\n",
    "    freq = np.array(np.fft.fftfreq(n)*SAMPLING_RATE)[:n//2]\n",
    "    power = np.abs(np.fft.fft(temporal_data))[:,:n//2]\n",
    "    return freq, power"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
